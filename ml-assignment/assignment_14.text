1. What is the concept of supervised learning? What is the significance of the name?

    Concept: Supervised learning is a type of machine learning where a model is trained on labeled data, meaning that the input data is paired with the correct output.
    Significance: The term "supervised" refers to the process of teaching the model using this labeled data, guiding it to learn the relationship between inputs and outputs.

2. In the hospital sector, offer an example of supervised learning.

    Example: Predicting patient readmission rates using historical patient data, where the labels indicate whether a patient was readmitted within a certain timeframe.

3. Give three supervised learning examples.

    Example 1: Email classification (spam vs. non-spam).
    Example 2: Image recognition (identifying objects in images).
    Example 3: Credit scoring (predicting the likelihood of loan default).

4. In supervised learning, what are classification and regression?

    Classification: A task where the output is a discrete label (e.g., classifying emails as spam or not spam).
    Regression: A task where the output is a continuous value (e.g., predicting house prices based on features).

5. Give some popular classification algorithms as examples.

    Examples:
        Logistic Regression
        Decision Trees
        Support Vector Machines (SVM)
        Random Forests
        k-Nearest Neighbors (kNN)

6. Briefly describe the SVM model.

    Description: The Support Vector Machine (SVM) is a supervised learning model that finds the optimal hyperplane to separate different classes in the feature space, maximizing the margin between classes.

7. In SVM, what is the cost of misclassification?

    Cost: The cost of misclassification refers to the penalty assigned to incorrect predictions, influencing the model's ability to balance accuracy and margin, often controlled by a parameter called C.

8. In the SVM model, define Support Vectors.

    Definition: Support Vectors are the data points closest to the decision boundary (hyperplane) that influence the position and orientation of the hyperplane. They are critical for defining the optimal boundary.

9. In the SVM model, define the kernel.

    Definition: A kernel is a function that transforms the input data into a higher-dimensional space to make it easier to separate classes. Common kernels include linear, polynomial, and radial basis function (RBF).

10. What are the factors that influence SVM's effectiveness?

    Factors:
        Choice of kernel
        Parameter tuning (C and gamma values)
        Quality and quantity of training data
        Feature scaling and preprocessing

11. What are the benefits of using the SVM model?

    Benefits:
        Effective in high-dimensional spaces
        Works well with a clear margin of separation
        Robust against overfitting, especially in high dimensions

12. What are the drawbacks of using the SVM model?

    Drawbacks:
        Computationally intensive for large datasets
        Less effective when classes are overlapping
        Choosing the right kernel can be complex

13. Notes should be written on...

    The kNN algorithm has a validation flaw: The kNN algorithm's performance can be overly sensitive to the choice of k and the distribution of the training data, leading to potential overfitting.
    In the kNN algorithm, the k value is chosen: The choice of k affects model complexity; a small k may lead to noise sensitivity, while a large k may smooth out important patterns.
    A decision tree with inductive bias: Decision trees can exhibit inductive bias by favoring simpler models (shorter trees) over more complex ones, often resulting in easier interpretation.

14. What are some of the benefits of the kNN algorithm?

    Benefits:
        Simple to implement and understand
        No assumptions about data distribution
        Naturally handles multi-class classification

15. What are some of the kNN algorithm's drawbacks?

    Drawbacks:
        Computationally expensive for large datasets due to distance calculations
        Sensitive to irrelevant or redundant features
        Requires careful selection of distance metrics

16. Explain the decision tree algorithm in a few words.

    Description: The decision tree algorithm recursively splits the data based on feature values to create a tree structure that represents decisions leading to an outcome.

17. What is the difference between a node and a leaf in a decision tree?

    Node: A decision point that represents a feature and its corresponding split.
    Leaf: A terminal node that represents a class label or output value after all splits.

18. What is a decision tree's entropy?

    Definition: Entropy is a measure of the impurity or randomness in the data at a node, guiding the decision tree's splitting criterion to maximize information gain.

19. In a decision tree, define knowledge gain.

    Definition: Knowledge gain (or information gain) measures the reduction in entropy after a dataset is split based on a feature, indicating how well the feature separates the classes.

20. Choose three advantages of the decision tree approach and write them down.

    Advantages:
        Easy to interpret and visualize
        Handles both numerical and categorical data
        Requires little data preprocessing

21. Make a list of three flaws in the decision tree process.

    Flaws:
        Prone to overfitting, especially with deep trees
        Can be unstable with small changes in data
        Biased towards features with more levels

22. Briefly describe the random forest model.

    Description: The random forest model is an ensemble learning method that constructs multiple decision trees during training and outputs the mode of their predictions, enhancing accuracy and reducing overfitting.
